{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentoría 'de cómo clasificar en géneros a las canciones'\n",
    "## Práctico II : Análisis de features de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas aclaraciones:\n",
    "- En 2) todos los pasos deberían poder hacerse en una línea, aunque si se complican y necesitan hacerlo en más no hay problema\n",
    "- En 3) les dejé un buen spoiler para que lo completen\n",
    "- Todas los conceptos y librerias que vamos a usar están documentados en el notebook\n",
    "- Esta vez vamos a ser más rígidos con los plazos, la entrega es el 05/08, la única instancia previa de corrección son las entregas ANTES de la fecha mencionada, caso contrario es la nota final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install spotipy\n",
    "!pip3 install pandas\n",
    "!pip3 install spacy\n",
    "!pip3 install pymusixmatch\n",
    "!pip3 install nltk\n",
    "\n",
    "# Agregar las librerías extra que se utilicen en esta celda y la siguiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias y acceso al API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "import spacy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import requests\n",
    "import json\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "client_id = '46b333d567314a89a6254b6c6b054be6'\n",
    "client_secret = '9d922c3613e441518349dcf55f7d5853'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #completar con el modelo que van a utilizar\n",
    "\n",
    "sns.set_context(context='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux methods\n",
    "\n",
    "def song_url_for_request(artist, song_title):\n",
    "    return \"https://api.lyrics.ovh/v1/\" + artist + '/' + song_title #str\n",
    "    #example use\n",
    "    #requests.get(song_url_for_request(\"Death Grips\", \"Hacker\"))\n",
    "    \n",
    "\n",
    "def songs_from_album_id(album_id):\n",
    "    songs = []\n",
    "    album = sp.album(album_id)\n",
    "    artist = album['artists'][0]['name']\n",
    "    for item in album['tracks']['items']:\n",
    "        track = {}\n",
    "        track[\"song_name\"] = item['name']\n",
    "        track[\"lyrics\"]=[]\n",
    "        track[\"song_id\"] = item['id']\n",
    "        track[\"album_name\"] = album['name']\n",
    "        track[\"album_id\"] = album[\"id\"]\n",
    "        track[\"artist\"] = artist\n",
    "        songs.append(track)\n",
    "    return songs    #songs:List[dict]\n",
    "\n",
    "\n",
    "\n",
    "def genres_by_artist_id(id): #id: str\n",
    "    artist = sp.artist(id)\n",
    "    genres = artist['genres']\n",
    "    return genres    #genres: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alternative hip hop',\n",
       " 'escape room',\n",
       " 'experimental hip hop',\n",
       " 'hip hop',\n",
       " 'industrial hip hop']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_by_artist_id(\"5RADpgYLOuS2ZxDq7ggYYH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta:\n",
    "- Por qué Death Grips destaca respecto al género de hip hop? \n",
    "- Cómo se refleja su caracter experimental en sus letras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Obtener datos para responder la pregunta\n",
    "Una vez obtenidas las letras de las canciones, las procesaremos de la siguiente manera:\n",
    "1. Tokenizar\n",
    "2. Remover las [stop-words](https://es.wikipedia.org/wiki/Palabra_vac%C3%ADa)\n",
    "3. [Lema](https://es.wikipedia.org/wiki/Lema_(ling%C3%BC%C3%ADstica))tizar las palabras que hayan quedado\n",
    "4. Organizar todo en un DataFrame de la forma Canción-Artista-Letra donde Letra es el resultado de 3.\n",
    "\n",
    "**Recomendación** : Usar un dataframe para su artista y otro para la competencia si es que eligierone esa opción, les va a ahorrar tiempo.\n",
    "\n",
    "**Aclaración** : Si plantearon una pregunta que no requiera los datos de la consigna, obtengan esos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build Death Grip's dataset. We'll be using lyrics from 5 albums;\n",
    "\n",
    "- No Love Deep Web\n",
    "- The money store\n",
    "- The powers that B\n",
    "- Bottomless Pit\n",
    "- Year of the snitch\n",
    "\n",
    "for a total of 70 songs. After sanitization, 69."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALBUM_IDS = [\"08aqY8lv4zx4uaqBUpMD8a\", \n",
    "              \"1PQDjdBpHPikAodJqjzm6a\",\n",
    "              \"5Y04ylQjDWsawOUJXzY4YO\",\n",
    "              \"4dIPUQHheyH9e6ioplvNT2\", \n",
    "              \"46eayJPxf1cBWWUqNa2MJJ\"]\n",
    "\n",
    "def lemmafy(doc):\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha:\n",
    "             lemmas.append(token.lemma_)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "#arm base dataset\n",
    "def build_from_album_ids(album_id_array):\n",
    "    all_songs = []\n",
    "    for album in tqdm.tqdm(ALBUM_IDS):\n",
    "        all_songs += songs_from_album_id(album)\n",
    "    return all_songs\n",
    "    \n",
    "all_songs = build_from_album_ids(ALBUM_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 31/70 [00:40<00:50,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have A Sad Cum BB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:31<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "#put song lyrics in dataset\n",
    "def add_lyrics_to_data(all_songs):\n",
    "    for song in tqdm.tqdm(all_songs):\n",
    "        response = requests.get(song_url_for_request(song[\"artist\"],song[\"song_name\"]))\n",
    "        json_data = json.loads(response.content)\n",
    "        try:\n",
    "            lyrics_raw = json_data[\"lyrics\"]\n",
    "            doc = nlp(lyrics_raw)\n",
    "            lemmed = lemmafy(doc)\n",
    "            song[\"lyrics\"]=lemmed\n",
    "        except: #found a song without lyrics!\n",
    "            print(song[\"song_name\"])\n",
    "            song[\"lyrics\"]=None\n",
    "    return all_songs\n",
    "\n",
    "all_songs = add_lyrics_to_data(all_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_songs_base = pd.DataFrame(all_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08aqY8lv4zx4uaqBUpMD8a</td>\n",
       "      <td>No Love Deep Web</td>\n",
       "      <td>Death Grips</td>\n",
       "      <td>[stone, wall, dog, gaze, duct, tape, ceiling, ...</td>\n",
       "      <td>0ynz4gps9rvFEsz1bz43Iz</td>\n",
       "      <td>Come Up And Get Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08aqY8lv4zx4uaqBUpMD8a</td>\n",
       "      <td>No Love Deep Web</td>\n",
       "      <td>Death Grips</td>\n",
       "      <td>[burn, burn, takin, turn, turn, know, burn, bu...</td>\n",
       "      <td>6fab5rAf9v58GR8P2Q1o1s</td>\n",
       "      <td>Lil Boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 album_id        album_name       artist  \\\n",
       "0  08aqY8lv4zx4uaqBUpMD8a  No Love Deep Web  Death Grips   \n",
       "1  08aqY8lv4zx4uaqBUpMD8a  No Love Deep Web  Death Grips   \n",
       "\n",
       "                                              lyrics                 song_id  \\\n",
       "0  [stone, wall, dog, gaze, duct, tape, ceiling, ...  0ynz4gps9rvFEsz1bz43Iz   \n",
       "1  [burn, burn, takin, turn, turn, know, burn, bu...  6fab5rAf9v58GR8P2Q1o1s   \n",
       "\n",
       "            song_name  \n",
       "0  Come Up And Get Me  \n",
       "1             Lil Boy  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanitize\n",
    "bool_series = pd.notnull(dg_songs_base[\"lyrics\"])\n",
    "dg_songs_base[bool_series].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos a compararlo con otros "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Encontrar los n-gramas (n= 1, 2) más comunes y usarlos en gráficos.\n",
    "Utilizando las librerías de la celda de abajo obtendremos los conjuntos de 1 y 2 palabras más comunes para cada artista con el que trabajaremos. Luego usaremos los unigramas para graficar una [word-cloud](https://i.imgur.com/8I8aJ1N.png) y un gráfico de distribución de frecuencia para unigramas y bigramas por autor (o de la forma que se adapte a su pregunta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 11080.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object ngrams at 0x7f266f463f68>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('wah',), 84),\n",
       " (('disappoint',), 13),\n",
       " (('Wah',), 12),\n",
       " (('chin',), 3),\n",
       " (('hold',), 3),\n",
       " (('job',), 3),\n",
       " (('fuck',), 3),\n",
       " (('tight',), 3),\n",
       " (('shot',), 2),\n",
       " (('life',), 2)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "count = Counter()\n",
    "for lyric in tqdm.tqdm(dg_songs_base[\"lyrics\"].values):\n",
    "    thing = ngrams(lyric,1)\n",
    "    try:\n",
    "        result = Counter(thing)\n",
    "    except:\n",
    "        print(thing)\n",
    "    #for item, count in sorted(result.items()):\n",
    "    #    if count>=10:\n",
    "    #        print(item,count)\n",
    "result.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('be', 'not'), 3),\n",
       " (('stone', 'wall'), 2),\n",
       " (('wall', 'dog'), 2),\n",
       " (('dog', 'gaze'), 2),\n",
       " (('gaze', 'duct'), 2),\n",
       " (('duct', 'tape'), 2),\n",
       " (('tape', 'ceiling'), 2),\n",
       " (('ceiling', 'Stucco'), 2),\n",
       " (('Stucco', 'cave'), 2),\n",
       " (('cave', 'illi'), 2),\n",
       " (('illi', 'okay'), 2),\n",
       " (('okay', 'okay'), 2),\n",
       " (('okay', 'feel'), 2),\n",
       " (('feel', 'high'), 2),\n",
       " (('high', 'abandon'), 2),\n",
       " (('abandon', 'building'), 2),\n",
       " (('building', 'daylight'), 2),\n",
       " (('daylight', 'midnight'), 2),\n",
       " (('midnight', 'lamp'), 2),\n",
       " (('lamp', 'light'), 2),\n",
       " (('light', 'seven'), 2),\n",
       " (('seven', 'murder'), 2),\n",
       " (('murder', 'window'), 2),\n",
       " (('window', 'exit'), 2),\n",
       " (('nosedive', 'life'), 2),\n",
       " (('life', 'second'), 2),\n",
       " (('second', 'suicide'), 2),\n",
       " (('suicide', 'be'), 2),\n",
       " (('not', 'stallion'), 2),\n",
       " (('stallion', 'surround'), 2),\n",
       " (('surround', 'Geiger'), 2),\n",
       " (('Geiger', 'count'), 2),\n",
       " (('count', 'go'), 2),\n",
       " (('go', 'shit'), 2),\n",
       " (('shit', 'bout'), 2),\n",
       " (('kamikaze', 'Fuck'), 2),\n",
       " (('Fuck', 'nazi'), 2),\n",
       " (('exit', 'Street'), 1),\n",
       " (('Street', 'nosedive'), 1),\n",
       " (('bout', 'ta'), 1),\n",
       " (('ta', 'kamikaze'), 1),\n",
       " (('nazi', 'world'), 1),\n",
       " (('world', 'come'), 1),\n",
       " (('come', 'knock'), 1),\n",
       " (('knock', 'fuck'), 1),\n",
       " (('fuck', 'world'), 1),\n",
       " (('world', 'fuck'), 1),\n",
       " (('fuck', 'body'), 1),\n",
       " (('body', 'know'), 1),\n",
       " (('know', 'will'), 1),\n",
       " (('will', 'long'), 1),\n",
       " (('long', 'feel'), 1),\n",
       " (('feel', 'nerve'), 1),\n",
       " (('nerve', 'wet'), 1),\n",
       " (('wet', 'brow'), 1),\n",
       " (('brow', 'Mood'), 1),\n",
       " (('Mood', 'tomb'), 1),\n",
       " (('tomb', 'red'), 1),\n",
       " (('red', 'moon'), 1),\n",
       " (('moon', 'heavy'), 1),\n",
       " (('heavy', 'sle'), 1),\n",
       " (('sle', 'jaw'), 1),\n",
       " (('jaw', 'shoot'), 1),\n",
       " (('shoot', 'window'), 1),\n",
       " (('window', 'yell'), 1),\n",
       " (('yell', 'come'), 1),\n",
       " (('come', 'epiphanic'), 1),\n",
       " (('epiphanic', 'amnesia'), 1),\n",
       " (('amnesia', 'Jimmy'), 1),\n",
       " (('Jimmy', 'Page'), 1),\n",
       " (('Page', 'castle'), 1),\n",
       " (('castle', 'planet'), 1),\n",
       " (('planet', 'Echo'), 1),\n",
       " (('Echo', 'astral'), 1),\n",
       " (('astral', 'Vinyl'), 1),\n",
       " (('Vinyl', 'lasso'), 1),\n",
       " (('lasso', 'Sacto'), 1),\n",
       " (('Sacto', 'asshole'), 1),\n",
       " (('asshole', 'fuck'), 1),\n",
       " (('fuck', 'stone'), 1),\n",
       " (('exit', 'street'), 1),\n",
       " (('street', 'nosedive'), 1),\n",
       " (('bout', 'kamikaze'), 1),\n",
       " (('nazi', 'come'), 1),\n",
       " (('come', 'life'), 1),\n",
       " (('life', 'fuck'), 1),\n",
       " (('fuck', 'be'), 1),\n",
       " (('not', 'thing'), 1),\n",
       " (('thing', 'hate'), 1),\n",
       " (('hate', 'tell'), 1),\n",
       " (('tell', 'time'), 1),\n",
       " (('time', 'wait'), 1),\n",
       " (('wait', 'gun'), 1),\n",
       " (('gun', 'head'), 1),\n",
       " (('head', 'blow'), 1),\n",
       " (('blow', 'smoke'), 1),\n",
       " (('smoke', 'face'), 1),\n",
       " (('face', 'think'), 1),\n",
       " (('think', 'get'), 1),\n",
       " (('get', 'take'), 1),\n",
       " (('take', 'come'), 1),\n",
       " (('come', 'tell'), 1),\n",
       " (('tell', 'hell'), 1),\n",
       " (('hell', 'head'), 1),\n",
       " (('head', 'thirteenth'), 1),\n",
       " (('thirteenth', 'bell'), 1),\n",
       " (('bell', 'dead'), 1),\n",
       " (('dead', 'asylum'), 1),\n",
       " (('asylum', 'pill'), 1),\n",
       " (('pill', 'force'), 1),\n",
       " (('force', 'fed'), 1),\n",
       " (('fed', 'Lyin'), 1),\n",
       " (('Lyin', 'strap'), 1),\n",
       " (('strap', 'bed'), 1),\n",
       " (('bed', 'Tongue'), 1),\n",
       " (('Tongue', 'cut'), 1),\n",
       " (('cut', 'mouth'), 1),\n",
       " (('mouth', 'reason'), 1),\n",
       " (('reason', 'chuck'), 1),\n",
       " (('chuck', 'river'), 1),\n",
       " (('river', 'edge'), 1),\n",
       " (('edge', 'think'), 1),\n",
       " (('think', 'fast'), 1),\n",
       " (('fast', 'tear'), 1),\n",
       " (('tear', 'gas'), 1),\n",
       " (('gas', 'fear'), 1),\n",
       " (('fear', 'masked'), 1),\n",
       " (('masked', 'figment'), 1),\n",
       " (('figment', 'fragmented'), 1),\n",
       " (('fragmented', 'mind'), 1),\n",
       " (('mind', 'enemy'), 1),\n",
       " (('enemy', 'step'), 1),\n",
       " (('step', 'die'), 1),\n",
       " (('die', 'Grand'), 1),\n",
       " (('Grand', 'delusion'), 1),\n",
       " (('delusion', 'magnify'), 1),\n",
       " (('magnify', 'fuck'), 1),\n",
       " (('fuck', 'truth'), 1),\n",
       " (('truth', 'waste'), 1),\n",
       " (('waste', 'time'), 1),\n",
       " (('time', 'good'), 1),\n",
       " (('good', 'bet'), 1),\n",
       " (('bet', 's'), 1),\n",
       " (('s', 'footstep'), 1),\n",
       " (('footstep', 'stair'), 1),\n",
       " (('stair', 'rest'), 1),\n",
       " (('rest', 'care'), 1),\n",
       " (('care', 'know'), 1),\n",
       " (('know', 'tryin'), 1),\n",
       " (('tryin', 'ta'), 1),\n",
       " (('ta', 'x'), 1),\n",
       " (('x', 'fuck'), 1),\n",
       " (('fuck', 'come'), 1)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams, bigrams\n",
    "import nltk\n",
    "result = []\n",
    "lyrics=[result+word for word in [line for line in dg_songs_base[\"lyrics\"].head(2).values]][0]\n",
    "#text_unigrams = [ngrams(sent, 1) for sent in lyric]\n",
    "#text_unigrams\n",
    "bi_tokens = bigrams(lyrics)\n",
    "counts = Counter(bi_tokens)\n",
    "#print([(item, counts.count(item)) for item in sorted(set(bi_tokens))])\n",
    "fdist = nltk.FreqDist(bi_tokens)\n",
    "for k,v in fdist.items():\n",
    "    print(k,v)\n",
    "#print(dg_songs_base[\"lyrics\"].head(2))\n",
    "counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Escribir un informe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este informe tiene que describir qué datos que obtuvieron, el volumen de estos (# de canciones del artista, # de canciones de la competencia, etc), una explicación de cómo estos se relacionan con la pregunta planteada, cómo ayudan a responderla y los resultados que obtuvieron. Usar la celda de abajo con formato markdown.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
