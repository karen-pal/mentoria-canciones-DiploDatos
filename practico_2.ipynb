{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentoría 'de cómo clasificar en géneros a las canciones'\n",
    "## Práctico II : Análisis de features de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Antes de empezar:**\n",
    "- [Instalar spaCy y el modelo de lenguaje con el que van a trabajar](https://spacy.io/models#quickstart)\n",
    "\n",
    "**Consideraciones:**\n",
    "- Se evalúa el estilo y prolijidad del código.\n",
    "- Se permite hacer trabajo extra, siempre y cuando las actividades básicas estén resueltas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas aclaraciones:\n",
    "- En 2) todos los pasos deberían poder hacerse en una línea, aunque si se complican y necesitan hacerlo en más no hay problema\n",
    "- En 3) les dejé un buen spoiler para que lo completen\n",
    "- Todas los conceptos y librerias que vamos a usar están documentados en el notebook\n",
    "- Esta vez vamos a ser más rígidos con los plazos, la entrega es el 05/08, la única instancia previa de corrección son las entregas ANTES de la fecha mencionada, caso contrario es la nota final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install spotipy\n",
    "!pip3 install pandas\n",
    "!pip3 install spacy\n",
    "!pip3 install pymusixmatch\n",
    "!pip3 install nltk\n",
    "\n",
    "# Agregar las librerías extra que se utilicen en esta celda y la siguiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias y acceso al API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "import spacy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import requests\n",
    "import json\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "client_id = '46b333d567314a89a6254b6c6b054be6'\n",
    "client_secret = '9d922c3613e441518349dcf55f7d5853'\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #completar con el modelo que van a utilizar\n",
    "\n",
    "sns.set_context(context='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux methods\n",
    "\n",
    "def song_url_for_request(artist, song_title):\n",
    "    return \"https://api.lyrics.ovh/v1/\" + artist + '/' + song_title #str\n",
    "    #example use\n",
    "    #requests.get(song_url_for_request(\"Death Grips\", \"Hacker\"))\n",
    "    \n",
    "\n",
    "def songs_from_album_id(album_id):\n",
    "    songs = []\n",
    "    album = sp.album(album_id)\n",
    "    artist = album['artists'][0]['name']\n",
    "    for item in album['tracks']['items']:\n",
    "        track = {}\n",
    "        track[\"song_name\"] = item['name']\n",
    "        track[\"lyrics\"]=[]\n",
    "        track[\"song_id\"] = item['id']\n",
    "        track[\"album_name\"] = album['name']\n",
    "        track[\"album_id\"] = album[\"id\"]\n",
    "        track[\"artist\"] = artist\n",
    "        songs.append(track)\n",
    "    return songs    #songs:List[dict]\n",
    "\n",
    "\n",
    "\n",
    "def genres_by_artist_id(id): #id: str\n",
    "    artist = sp.artist(id)\n",
    "    genres = artist['genres']\n",
    "    return genres    #genres: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alternative hip hop',\n",
       " 'escape room',\n",
       " 'experimental hip hop',\n",
       " 'hip hop',\n",
       " 'industrial hip hop']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_by_artist_id(\"5RADpgYLOuS2ZxDq7ggYYH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta:\n",
    "- Por qué Death Grips destaca respecto al género de hip hop? \n",
    "- Cómo se refleja su caracter experimental en sus letras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in lyrics:\n",
    "    token.lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Obtener datos para responder la pregunta\n",
    "Una vez obtenidas las letras de las canciones, las procesaremos de la siguiente manera:\n",
    "1. Tokenizar\n",
    "2. Remover las [stop-words](https://es.wikipedia.org/wiki/Palabra_vac%C3%ADa)\n",
    "3. [Lema](https://es.wikipedia.org/wiki/Lema_(ling%C3%BC%C3%ADstica))tizar las palabras que hayan quedado\n",
    "4. Organizar todo en un DataFrame de la forma Canción-Artista-Letra donde Letra es el resultado de 3.\n",
    "\n",
    "**Recomendación** : Usar un dataframe para su artista y otro para la competencia si es que eligierone esa opción, les va a ahorrar tiempo.\n",
    "\n",
    "**Aclaración** : Si plantearon una pregunta que no requiera los datos de la consigna, obtengan esos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build Death Grip's dataset. We'll be using lyrics from 5 albums;\n",
    "\n",
    "- No Love Deep Web\n",
    "- The money store\n",
    "- The powers that B\n",
    "- Bottomless Pit\n",
    "- Year of the snitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALBUM_IDS = [\"08aqY8lv4zx4uaqBUpMD8a\", \n",
    "              \"1PQDjdBpHPikAodJqjzm6a\",\n",
    "              \"5Y04ylQjDWsawOUJXzY4YO\",\n",
    "              \"4dIPUQHheyH9e6ioplvNT2\", \n",
    "              \"46eayJPxf1cBWWUqNa2MJJ\"]\n",
    "\n",
    "def lemmafy(doc):\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha:\n",
    "             lemmas.append(token.lemma_)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "#arm base dataset\n",
    "def build_from_album_ids(album_id_array):\n",
    "    all_songs = []\n",
    "    for album in tqdm.tqdm(ALBUM_IDS):\n",
    "        all_songs += songs_from_album_id(album)\n",
    "    return all_songs\n",
    "    \n",
    "all_songs = build_from_album_ids(ALBUM_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 31/70 [00:40<00:50,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have A Sad Cum BB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [01:29<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "#put song lyrics in dataset\n",
    "def add_lyrics_to_data(all_songs):\n",
    "    for song in tqdm.tqdm(all_songs):\n",
    "        response = requests.get(song_url_for_request(song[\"artist\"],song[\"song_name\"]))\n",
    "        json_data = json.loads(response.content)\n",
    "        try:\n",
    "            lyrics_raw = json_data[\"lyrics\"]\n",
    "            doc = nlp(lyrics_raw)\n",
    "            lemmed = lemmafy(doc)\n",
    "            song[\"lyrics\"]=lemmed\n",
    "        except: #found a song without lyrics!\n",
    "            print(song[\"song_name\"])\n",
    "            song[\"lyrics\"]=None\n",
    "    return all_songs\n",
    "\n",
    "all_songs = add_lyrics_to_data(all_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_songs_base = pd.DataFrame(all_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08aqY8lv4zx4uaqBUpMD8a</td>\n",
       "      <td>No Love Deep Web</td>\n",
       "      <td>Death Grips</td>\n",
       "      <td>[stone, wall, dog, gaze, duct, tape, ceiling, ...</td>\n",
       "      <td>0ynz4gps9rvFEsz1bz43Iz</td>\n",
       "      <td>Come Up And Get Me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08aqY8lv4zx4uaqBUpMD8a</td>\n",
       "      <td>No Love Deep Web</td>\n",
       "      <td>Death Grips</td>\n",
       "      <td>[burn, burn, takin, turn, turn, know, burn, bu...</td>\n",
       "      <td>6fab5rAf9v58GR8P2Q1o1s</td>\n",
       "      <td>Lil Boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 album_id        album_name       artist  \\\n",
       "0  08aqY8lv4zx4uaqBUpMD8a  No Love Deep Web  Death Grips   \n",
       "1  08aqY8lv4zx4uaqBUpMD8a  No Love Deep Web  Death Grips   \n",
       "\n",
       "                                              lyrics                 song_id  \\\n",
       "0  [stone, wall, dog, gaze, duct, tape, ceiling, ...  0ynz4gps9rvFEsz1bz43Iz   \n",
       "1  [burn, burn, takin, turn, turn, know, burn, bu...  6fab5rAf9v58GR8P2Q1o1s   \n",
       "\n",
       "            song_name  \n",
       "0  Come Up And Get Me  \n",
       "1             Lil Boy  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanitize\n",
    "bool_series = pd.notnull(dg_songs_base[\"lyrics\"])\n",
    "dg_songs_base[bool_series].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Encontrar los n-gramas (n= 1, 2) más comunes y usarlos en gráficos.\n",
    "Utilizando las librerías de la celda de abajo obtendremos los conjuntos de 1 y 2 palabras más comunes para cada artista con el que trabajaremos. Luego usaremos los unigramas para graficar una [word-cloud](https://i.imgur.com/8I8aJ1N.png) y un gráfico de distribución de frecuencia para unigramas y bigramas por autor (o de la forma que se adapte a su pregunta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 8729.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object ngrams at 0x7f6cf8c6d0a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('wah',), 84),\n",
       " (('Wah',), 12),\n",
       " (('disappointed',), 10),\n",
       " (('disappoint',), 3),\n",
       " (('chin',), 3),\n",
       " (('hold',), 3),\n",
       " (('job',), 3),\n",
       " (('fuck',), 3),\n",
       " (('tight',), 3),\n",
       " (('shot',), 2)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "\n",
    "for lyric in tqdm.tqdm(dg_songs_base[\"lyrics\"].values):\n",
    "    thing = ngrams(lyric,1)\n",
    "    try:\n",
    "        result = Counter(thing)\n",
    "    except:\n",
    "        print(thing)\n",
    "    #for item, count in sorted(result.items()):\n",
    "    #    if count>=10:\n",
    "    #        print(item,count)\n",
    "result.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Escribir un informe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este informe tiene que describir qué datos que obtuvieron, el volumen de estos (# de canciones del artista, # de canciones de la competencia, etc), una explicación de cómo estos se relacionan con la pregunta planteada, cómo ayudan a responderla y los resultados que obtuvieron. Usar la celda de abajo con formato markdown.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
